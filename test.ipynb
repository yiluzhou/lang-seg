{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# streamlit run lseg_app.py -- --weights=\"/mnt/g/Datasets/ADEChallengeData2016/demo_e200.ckpt\" --data-path=\"/mnt/g/Datasets/ADEChallengeData2016/\"\n",
    "\n",
    "\n",
    "# /home/yilu/miniconda3/envs/langseg/lib/python3.11/site-packages/encoding/nn/__init__.py\n",
    "\n",
    "# https://github.com/zhanghang1989/PyTorch-Encoding/compare/master...johndavidbustard:PyTorch-Encoding:master\n",
    "# tried:\n",
    "# https://github.com/krrish94/PyTorch-Encoding/archive/refs/heads/master.zip\n",
    "# \n",
    "# https://github.com/Zacchaeus00/PyTorch-Encoding/archive/refs/heads/master.zip\n",
    "from encoding import gpu\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gradient_clip_val', 'callbacks', 'overfit_batches', 'gradient_clip_algorithm', 'enable_checkpointing', 'min_epochs', 'check_val_every_n_epoch', 'plugins', 'benchmark', 'max_steps', 'fast_dev_run', 'use_distributed_sampler', 'detect_anomaly', 'barebones', 'reload_dataloaders_every_n_epochs', 'num_sanity_val_steps', 'sync_batchnorm', 'logger', 'max_time', 'limit_predict_batches', 'inference_mode', 'devices', 'num_nodes', 'max_epochs', 'log_every_n_steps', 'enable_model_summary', 'strategy', 'default_root_dir', 'val_check_interval', 'limit_test_batches', 'accelerator', 'precision', 'limit_val_batches', 'accumulate_grad_batches', 'enable_progress_bar', 'profiler', 'deterministic', 'min_steps', 'limit_train_batches'}\n",
      "{'num_nodes': 1, 'accumulate_grad_batches': 2, 'max_epochs': 240, 'accelerator': 'ddp', 'benchmark': True, 'sync_batchnorm': True, 'callbacks': [], 'logger': []}\n"
     ]
    }
   ],
   "source": [
    "# !python --version\n",
    "import inspect\n",
    "from pytorch_lightning import Trainer\n",
    "\n",
    "# Extract the set of accepted arguments from the Trainer's signature\n",
    "accepted_args = set(inspect.signature(Trainer).parameters.keys())\n",
    "print(accepted_args)\n",
    "\n",
    "trainer_args = {'num_nodes': 1, 'exp_name': 'lseg_ade20k_l16', 'dry_run': False, 'no_resume': False, 'accumulate_grad_batches': 2, \n",
    "                'max_epochs': 240, 'project_name': 'lightseg', 'data_path': '../datasets', 'dataset': 'ade20k', 'batch_size': 1, \n",
    "                'base_lr': 0.004, 'momentum': 0.9, 'weight_decay': 0.0001, 'aux': False, 'aux_weight': 0.2, 'se_loss': False, 'se_weight': 0.2, \n",
    "                'midasproto': False, 'ignore_index': -1, 'augment': False, 'backbone': 'clip_vitl16_384', 'num_features': 256, 'dropout': 0.1, \n",
    "                'finetune_weights': None, 'no_scaleinv': False, 'no_batchnorm': False, 'widehead': True, 'widehead_hr': False, 'arch_option': 0, \n",
    "                'block_depth': 0, 'activation': 'lrelu', 'gpus': -1, 'accelerator': 'ddp', 'benchmark': True, 'resume_from_checkpoint': None, \n",
    "                'version': 0, 'sync_batchnorm': True, 'callbacks': [], 'wandb_id': '9r6y3ocp', 'logger': []}\n",
    "\n",
    "# Extract the set of keys from trainer_args\n",
    "provided_args = set(trainer_args.keys())\n",
    "\n",
    "# Find unexpected keywords\n",
    "unexpected_args = provided_args - accepted_args\n",
    "\n",
    "# Remove unexpected keywords from trainer_args\n",
    "for arg in unexpected_args:\n",
    "    trainer_args.pop(arg, None)\n",
    "\n",
    "print(trainer_args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langseg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
